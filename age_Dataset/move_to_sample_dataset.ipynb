{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda9a4bf",
   "metadata": {},
   "source": [
    "- train 120000개, test 15000개를 랜덤으로 선택\n",
    "- 파일을 옮길 때 중복 파일, 없는 파일 등의 오류로 인해 데이터 손실 발생\n",
    "- 최종적으로 train 119383개, test 14928개의 데이터를 샘플로 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2c14e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D:\\ksponspeech\\자유대화 음성(소아, 유아)\\Training\\audio\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D:\\ksponspeech\\자유대화 음성(소아, 유아)\\Training\\audio\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D:\\ksponspeech\\자유대화 음성(노인남녀)\\Training\\audio\\AI...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>D:\\ksponspeech\\자유대화 음성(소아, 유아)\\Training\\audio\\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>D:\\ksponspeech\\자유대화 음성(일반남녀)\\Training\\audio\\AI...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         audio_path  age  gender\n",
       "0           0  D:\\ksponspeech\\자유대화 음성(소아, 유아)\\Training\\audio\\...  0.0     1.0\n",
       "1           1  D:\\ksponspeech\\자유대화 음성(소아, 유아)\\Training\\audio\\...  0.0     0.0\n",
       "2           2  D:\\ksponspeech\\자유대화 음성(노인남녀)\\Training\\audio\\AI...  2.0     0.0\n",
       "3           3  D:\\ksponspeech\\자유대화 음성(소아, 유아)\\Training\\audio\\...  0.0     0.0\n",
       "4           4  D:\\ksponspeech\\자유대화 음성(일반남녀)\\Training\\audio\\AI...  1.0     1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"C:\\\\Users\\\\USER\\\\Desktop\\\\speech-classification\\\\age_Dataset\\\\\"\n",
    "train_df = pd.read_csv(path+\"train_df.csv\")\n",
    "test_df = pd.read_csv(path+\"test_df.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ac8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "destination = \"C:\\\\Users\\\\USER\\\\Desktop\\\\speech-classification\\\\age_Dataset\\\\sample_dataset\\\\train\\\\\"\n",
    "for target_file in train_df['audio_path']:\n",
    "    try: \n",
    "        shutil.move(target_file, destination)\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "destination = \"C:\\\\Users\\\\USER\\\\Desktop\\\\speech-classification\\\\age_Dataset\\\\sample_dataset\\\\test\\\\\"\n",
    "for target_file in test_df['audio_path']:\n",
    "    try:\n",
    "        shutil.move(target_file, destination)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4dc6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134311\n"
     ]
    }
   ],
   "source": [
    "# train_file, test_file이 모두 ./sample_dataset/train/ 디렉토리에 옮겨짐\n",
    "train_file_list = os.listdir(\"./sample_dataset/train\")\n",
    "print(len(train_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cca2530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_file_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0026c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 15000/15000 [04:17<00:00, 58.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#test 파일이 모두 ./sample_datset/train 디렉토리에 있음을 확인\n",
    "nothing = 0\n",
    "test_file = 0\n",
    "\n",
    "from tqdm import tqdm\n",
    "for target_file_path in tqdm(test_df['audio_path']):\n",
    "    idx = target_file_path.rfind('\\\\')\n",
    "    filename = target_file_path[idx+1:]\n",
    "    for train_file in train_file_list:\n",
    "        if filename not in train_file:\n",
    "            nothing+=1\n",
    "        else:\n",
    "            test_file+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8ea7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_file:  15000\n"
     ]
    }
   ],
   "source": [
    "print(\"test_file: \", test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39650618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노인남여_노인대화02_F_e7222879_61_수도권_실내_01535.wav\n"
     ]
    }
   ],
   "source": [
    "print(train_file_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9aa384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 15000/15000 [00:17<00:00, 835.21it/s]\n"
     ]
    }
   ],
   "source": [
    "#./sample_dataset/train/에 있는 test 파일들을 ./sample_dataset/test/ 디렉토리로 이동\n",
    "import shutil\n",
    "for target_file_path in tqdm(test_df['audio_path']):\n",
    "    idx = target_file_path.rfind('\\\\')\n",
    "    filename = target_file_path[idx+1:]\n",
    "    try:\n",
    "        if filename in train_file_list:\n",
    "            shutil.move(\"./sample_dataset/train/\"+filename, \"./sample_dataset/test/\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b11f6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_files:  119383\n",
      "num of test_files:  14928\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(\"./sample_dataset/train\")\n",
    "test_files = os.listdir(\"./sample_dataset/test\")\n",
    "print(\"num of train_files: \", len(train_files))\n",
    "print(\"num of test_files: \", len(test_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kspeech4",
   "language": "python",
   "name": "kspeech4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
