{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186a0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torchaudio\n",
    "import torchaudio.transforms as at\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_path_list(path, gender):\n",
    "    file_path_list = list()\n",
    "    for env in os.listdir(path):\n",
    "        env_path = path+'\\\\'+env\n",
    "        for gender_folder in os.listdir(env_path):\n",
    "            gender_folder_path = env_path +'\\\\'+gender\n",
    "            for gender_file in os.listdir(gender_folder_path):\n",
    "                gender_file_path = gender_folder_path+'\\\\'+gender_file\n",
    "                file_path_list.append(gender_file_path)\n",
    "    return file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89619c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# dataset_dir = \"C:\\\\Users\\\\USER\\\\Desktop\\\\kspeech\\\\dataset\\\\freeconversation_common\\\\Validation\\\\wave_and_txt\\\\일반남여_일반통합01_F_KKJ00_47_수도권_녹음\"\n",
    "# transcripts_path_list = list(glob.glob(dataset_dir+\"\\\\*.txt\"))\n",
    "# audio_path_list = list(glob.glob(dataset_dir+\"\\\\*.wav\"))\n",
    "# print(len(transcripts_path_list))\n",
    "# print(len(audio_path_list))\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "transcript_path = \"D:\\\\ksponspeech\\\\자유대화 음성(일반남녀)\\\\Training\\\\transcript\"\n",
    "audio_path = \"D:\\\\ksponspeech\\\\자유대화 음성(일반남녀)\\\\Training\\\\audio\"\n",
    "\n",
    "female_transcript_path_list = dataset_path_list(transcript_path, \"Female\")\n",
    "female_audio_path_list = dataset_path_list(audio_path, \"Female\")\n",
    "print(len(female_transcript_path_list))\n",
    "print(len(female_audio_path_list))\n",
    "\n",
    "male_transcript_path_list = dataset_path_list(transcript_path, \"Male\")\n",
    "male_audio_path_list = dataset_path_list(audio_path, \"Male\")\n",
    "print(len(male_transcript_path_list))\n",
    "print(len(male_audio_path_list))\n",
    "\n",
    "whole_transcript_path_list = list()\n",
    "whole_transcript_path_list.extend(female_transcript_path_list)\n",
    "whole_transcript_path_list.extend(male_transcript_path_list)\n",
    "whole_audio_path_list = list()\n",
    "whole_audio_path_list.extend(female_audio_path_list)\n",
    "whole_audio_path_list.extend(male_audio_path_list)\n",
    "print(len(whole_transcript_path_list))\n",
    "print(len(whole_audio_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# print(len(whole_audio_path_list)): 4557966\n",
    "random.shuffle(whole_audio_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3379b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30만개 랜덤으로 골라냄.\n",
    "train_whole_audio_path_list, test_whole_audio_path_list = whole_audio_path_list[:210000], whole_audio_path_list[210000:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8883a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_whole_transcript_list = list()\n",
    "for item in train_whole_audio_path_list:\n",
    "    start = item.find(\"o\\\\\")\n",
    "    end = item.rfind(\".wav\")\n",
    "    file_path = \"D:\\\\ksponspeech\\\\자유대화 음성(일반남녀)\\\\Training\\\\transcript\\\\\"+item[start+2:end]+\".json.txt\"\n",
    "    if Path(file_path).exists() == True:\n",
    "        train_whole_transcript_list.append(file_path)\n",
    "    else: \n",
    "        train_whole_audio_path_list.remove(item)\n",
    "    \n",
    "test_whole_transcript_list = list()\n",
    "for item in test_whole_audio_path_list:\n",
    "    start = item.find(\"o\\\\\")\n",
    "    end = item.rfind(\".wav\")\n",
    "    file_path = \"D:\\\\ksponspeech\\\\자유대화 음성(일반남녀)\\\\Training\\\\transcript\\\\\"+item[start+2:end]+\".json.txt\"\n",
    "    if Path(file_path).exists() == True:\n",
    "        test_whole_transcript_list.append(file_path)\n",
    "    else:\n",
    "        test_whole_audio_path_list.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021fccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_whole_audio_path_list))\n",
    "print(len(test_whole_audio_path_list))\n",
    "print(len(train_whole_transcript_list))\n",
    "print(len(test_whole_transcript_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset\n",
    "train_female_audio_list = list()\n",
    "train_male_audio_list = list()\n",
    "\n",
    "for item in train_whole_audio_path_list:\n",
    "    if item.find('_F')>=0:\n",
    "        train_female_audio_list.append(item)\n",
    "    elif item.find('_M')>=0:\n",
    "        train_male_audio_list.append(item)\n",
    "    else:\n",
    "        print(\"ERROR!\", item)\n",
    "\n",
    "train_female_transcript_list = list()\n",
    "train_male_transcript_list = list()\n",
    "\n",
    "for item in train_whole_transcript_list:\n",
    "    if item.find('_F')>=0:\n",
    "        train_female_transcript_list.append(item)\n",
    "    elif item.find('_M')>=0:\n",
    "        train_male_transcript_list.append(item)\n",
    "    else:\n",
    "        print(\"ERROR!\", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9414bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_whole_df = pd.DataFrame({'audio_path':list(), 'transcript_path':list(), 'gender':list()})\n",
    "for item in train_whole_audio_path_list:\n",
    "    start = item.find(\"o\\\\\")\n",
    "    end = item.rfind(\".wav\")\n",
    "    transcript_path = \"D:\\\\ksponspeech\\\\자유대화 음성(일반남녀)\\\\Training\\\\transcript\\\\\"+item[start+2:end]+\".json.txt\"\n",
    "    audio_path = item\n",
    "    if item.find('_F')>=0:\n",
    "        gender = 'F'\n",
    "    elif item.find('_M')>=0:\n",
    "        gender = 'M'\n",
    "    else:\n",
    "        print(\"ERROR!\", item)\n",
    "    tmp_df = pd.DataFrame({'audio_path':[audio_path], 'transcript_path':[transcript_path], 'gender':[gender]})\n",
    "    train_whole_df = pd.concat([train_whole_df, tmp_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_whole_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbaebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_whole_df = pd.DataFrame({'audio_path':list(), 'transcript_path':list(), 'gender':list()})\n",
    "for item in test_whole_audio_path_list:\n",
    "    start = item.find(\"o\\\\\")\n",
    "    end = item.rfind(\".wav\")\n",
    "    transcript_path = \"D:\\\\ksponspeech\\\\자유대화 음성(일반남녀)\\\\Training\\\\transcript\\\\\"+item[start+2:end]+\".json.txt\"\n",
    "    audio_path = item\n",
    "    if item.find('_F')>=0:\n",
    "        gender = 'F'\n",
    "    elif item.find('_M')>=0:\n",
    "        gender = 'M'\n",
    "    else:\n",
    "        print(\"ERROR!\", item)\n",
    "    tmp_df = pd.DataFrame({'audio_path':[audio_path], 'transcript_path':[transcript_path], 'gender':[gender]})\n",
    "    test_whole_df = pd.concat([test_whole_df, tmp_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16057853",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_whole_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_whole_df.to_csv(\"C:\\\\Users\\\\USER\\\\Desktop\\\\kspeech\\\\Whisper\\\\train_whole_df.csv\")\n",
    "test_whole_df.to_csv(\"C:\\\\Users\\\\USER\\\\Desktop\\\\kspeech\\\\Whisper\\\\test_whole_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_female_audio_list))\n",
    "print(len(train_male_audio_list))\n",
    "print(len(train_female_transcript_list))\n",
    "print(len(train_male_transcript_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d5c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kspeech4",
   "language": "python",
   "name": "kspeech4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
